colnames(volume) <- tickers
colnames(adj.close) <- tickers
# Return the ouput
return(list(open=open, high=hi, low=low, close=close, volume=volume, adj.close=adj.close))
}
data.loading("DATA", "2019-05-01", "2019-06-03")
library(MASS)
library(dplyr)
# Carga de datos
data <- Boston %>%
dplyr::select(lstat,medv)
names(data)[1] <- "input"
names(data)[2] <- "output"
str(data)
# Función para obtener un boot sample
get_boot_sample <- function(x, dataset, size) {
return(sample_n(dataset, size = size, replace = TRUE))
}
# Función para ajustar modelo de grado 'degree'
fit_lm <- function(dataset, degree = 2) {
if (degree == 0) {
fit <- lm("output ~ 1", data = dataset)
} else {
formula <- paste0("I(","input^", 1:degree, ")", collapse = '+')
formula <- paste0("output ~ ", formula)
fit <- lm(formula, data = dataset)
}
return(fit)
}
# Esta función genera los valores de pronóstico para las gráficas
model_fitted_plotdata <- function(fit){
xaxis <- seq(min(data$input), max(data$input), by=0.01)
yaxis <- predict(fit, tibble(input = xaxis))
return(tibble(input = xaxis, output = yaxis))
}
model_fitted_values <- function(fit, dataset) {
xaxis <- dataset$input
yaxis <- predict(fit, tibble(input = xaxis))
return(tibble(input = xaxis, output = dataset$output, f = yaxis))
}
# Definiciones para el ejercicio de bootstrap
nboots <- 100
bootsize <- nrow(data)
# Obtenemos las muestras de bootstrap en una lista
boot_samples <- lapply(1 : nboots, get_boot_sample, dataset = data, size = bootsize)
# Obtenemos una lista de modelos ajustados con la muestra y obtenemos los valores ajustados
all.models <- lapply(boot_samples, fit_lm, degree = 10)
all.model.predictions <- lapply(all.models, model_fitted_plotdata)
# Obtenemos todas las funciones de hipótesis en una misma estructura
all.hypothesis <- bind_rows(all.model.predictions, .id = "boot")
# Obtenemos la media con dplyr
mean_pred <- all.hypothesis %>%
group_by(input) %>%
summarise(mean_fn = mean(output))
# Graficamos las hipótesis en gris y los valores promedio en rojo
plot(data, pch=20, cex=0.25)
for(i in 1:nboots) {
points(all.model.predictions[[i]], col='gray', type='l')
}
points(mean_pred, type = 'l', col='red')
datatest <- data
for (i in 1:100) {
modelo_str <- paste("f", i, sep = "")
datatest[[modelo_str]] <- predict(all.models[[i]], tibble(input = datatest$input))
}
head(datatest)
f_hat_mean <- datatest %>%
dplyr::select(starts_with("f")) %>%
rowSums / 100
varX <- (1/(100-1)) * rowSums((datatest %>% dplyr::select(starts_with("f")) - f_hat_mean)^2)
varianza <- mean(varX)
varianza
sesgoX <- (datatest$output - f_hat_mean)^2
sesgo <- mean(sesgoX)
sesgo
# Función para la varianza
sesgo.varianza.fn <- function(grado, df, B, n) {
print(sprintf("Generando modelo de complejidad %d", grado))
# Obtenemos las muestras de bootstrap en una lista
boot_samples <- lapply(1 : B, get_boot_sample, dataset = df, size = n)
# Obtenemos una lista de modelos ajustados con la muestra y obtenemos los valores ajustados
all.models <- lapply(boot_samples, fit_lm, degree = grado)
# Generamos los valores ajustados de todos los modelos
all.models.predictions <- lapply(all.models, predict, tibble(input = data$input))
all.models.predictions <- do.call(cbind, all.models.predictions)
# Computamos los valores ajustados promedio
f_hat_mean <- rowSums(all.models.predictions) / B
# Obtenemos la varianza
varX <- (1/(B-1)) * rowSums((all.models.predictions - f_hat_mean)^2)
varianza <- mean(varX)
# Obtener el sesgo
sesgoX <- (datatest$output - f_hat_mean)^2
sesgo <- mean(sesgoX)
return(c("Sesgo" = sesgo, "Varianza" = varianza))
}
cmplx = 11
modl.var <- lapply(c(0:cmplx), sesgo.varianza.fn, df = data, B = 1000, n = nrow(data))
dataComplex <- as.data.frame(do.call(rbind, modl.var))
dataComplex[["GradoPolinomio"]] = 0:cmplx
dataComplex
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red",
xlab = "Grado del polinomio")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
legend(2, 80, c("Sesgo^2", "Varianza"))
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red",
xlab = "Grado del polinomio")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
legend(2, 80, c("Sesgo^2", "Varianza"))
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red",
xlab = "Grado del polinomio")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
legend(2, 80, c("Sesgo^2", "Varianza"), col = c("red", "blue"))
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red",
xlab = "Grado del polinomio")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
legend(2, 80, legend = c("Sesgo^2", "Varianza"), col = c("red", "blue"))
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red",
xlab = "Grado del polinomio")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
legend(2, 80, legend = c("Sesgo^2", "Varianza"), col = c("red", "blue"),  lty=1:2, cex=0.8)
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red",
xlab = "Grado del polinomio")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
legend(2, 80, legend = c("Sesgo^2", "Varianza"), col = c("red", "blue"),  lty=1, cex=0.8)
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red",
xlab = "Grado del polinomio")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
legend(2, 80, legend = c("Sesgo^2", "Varianza"), col = c("red", "blue"),  lty=1, cex=1.2)
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red",
xlab = "Grado del polinomio", ylab = "Varianza y sesgo^2")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
legend(2, 80, legend = c("Sesgo^2", "Varianza"), col = c("red", "blue"),  lty=1, cex=1.2)
setwd("E:/Galileo/EconometriaR/proyectoChanceOfAdmit")
setwd("E:/Galileo/EconometriaR/StepwiseSelection")
library(dplyr)
library(MASS)
library(caret)
# Ajusta el modelo para Ylabel con el vector de predictores,
# utilizando el dataset data
fit.model.fn <- function(candidate_predictors, predictors, Ylabel, data) {
# Crear la formula
formula <- paste(Ylabel, "~", paste(c(predictors, candidate_predictors), collapse = "+"), collapse = "")
# Ajustar el modelo
model <- lm(formula, data = data)
# Valores ajustados
Ypred <- predict(model, data)
mse <- mean((Ypred - data[[Ylabel]])^2)
return(mse)
}
dataset <- Boston
target <- "medv"
# Arreglo de predictoras candidatas
predictors <- setdiff(colnames(dataset), target)
# Predictoras iniciales
init_predictors <- c("1")
listaPredictoras <- list()
modelosEstimados <- 0
for (i in 1:(length(predictors))) {
# Obtener la lista de rss con cada variable
ss <- sapply(predictors, fit.model.fn,
predictors = init_predictors,
Ylabel = "medv", data = dataset)
modelosEstimados <- modelosEstimados + length(ss)
# Obtener el índice de variables que minimiza el ss
i.min <- which.min(ss)
# Agregar a la lista de predictores fijos y quitar de los candidatos
init_predictors <- union(init_predictors, predictors[i.min])
predictors <- setdiff(predictors, predictors[i.min])
print(paste("Mejor modelo de ", i, " variables", collapse = ""))
print(init_predictors)
listaPredictoras[[i]] <- init_predictors
}
forward.stepwise.fn <- function(dataset, target, p) {
# Arreglo de predictoras candidatas
predictors <- setdiff(colnames(dataset), target)
# Predictoras iniciales
init_predictors <- c("1")
# Variables auxiliares
listaPredictoras <- list()
modelosEstimados <- 0
# Validación de p
if (p > length(predictors)) {
p = 2
}
for (i in 1:p) {
# Obtener la lista de rss con cada variable
ss <- sapply(predictors, fit.model.fn,
predictors = init_predictors,
Ylabel = "medv", data = dataset)
modelosEstimados <- modelosEstimados + length(ss)
# Obtener el índice de variables que minimiza el ss
i.min <- which.min(ss)
# Agregar a la lista de predictores fijos y quitar de los candidatos
init_predictors <- union(init_predictors, predictors[i.min])
predictors <- setdiff(predictors, predictors[i.min])
#print(paste("Mejor modelo de ", i, " variables", collapse = ""))
#print(init_predictors)
# Guardar las predictoras del modelo de i variables
listaPredictoras[[i]] <- init_predictors
}
print(paste("Modelos estimados ", modelosEstimados, collapse = ""))
}
rm(list=ls())
# Ajusta el modelo para Ylabel con el vector de predictores,
# utilizando el dataset data
fit.model.fn <- function(candidate_predictors, predictors, Ylabel, data) {
# Crear la formula
formula <- paste(Ylabel, "~", paste(c(predictors, candidate_predictors), collapse = "+"), collapse = "")
# Ajustar el modelo
model <- lm(formula, data = data)
# Valores ajustados
Ypred <- predict(model, data)
mse <- mean((Ypred - data[[Ylabel]])^2)
return(mse)
}
forward.stepwise.fn <- function(dataset, target, p) {
# Arreglo de predictoras candidatas
predictors <- setdiff(colnames(dataset), target)
# Predictoras iniciales
init_predictors <- c("1")
# Variables auxiliares
listaPredictoras <- list()
modelosEstimados <- 0
# Validación de p
if (p > length(predictors)) {
p = 2
}
for (i in 1:p) {
# Obtener la lista de rss con cada variable
ss <- sapply(predictors, fit.model.fn,
predictors = init_predictors,
Ylabel = "medv", data = dataset)
modelosEstimados <- modelosEstimados + length(ss)
# Obtener el índice de variables que minimiza el ss
i.min <- which.min(ss)
# Agregar a la lista de predictores fijos y quitar de los candidatos
init_predictors <- union(init_predictors, predictors[i.min])
predictors <- setdiff(predictors, predictors[i.min])
#print(paste("Mejor modelo de ", i, " variables", collapse = ""))
#print(init_predictors)
# Guardar las predictoras del modelo de i variables
listaPredictoras[[i]] <- init_predictors
}
print(paste("Modelos estimados ", modelosEstimados, collapse = ""))
}
listaVar <- forward.stepwise.fn(dataset = Boston, target = "medv", 5)
forward.stepwise.fn <- function(dataset, target, p) {
# Arreglo de predictoras candidatas
predictors <- setdiff(colnames(dataset), target)
# Predictoras iniciales
init_predictors <- c("1")
# Variables auxiliares
listaPredictoras <- list()
modelosEstimados <- 0
# Validación de p
if (p > length(predictors)) {
p = 2
}
for (i in 1:p) {
# Obtener la lista de rss con cada variable
ss <- sapply(predictors, fit.model.fn,
predictors = init_predictors,
Ylabel = "medv", data = dataset)
modelosEstimados <- modelosEstimados + length(ss)
# Obtener el índice de variables que minimiza el ss
i.min <- which.min(ss)
# Agregar a la lista de predictores fijos y quitar de los candidatos
init_predictors <- union(init_predictors, predictors[i.min])
predictors <- setdiff(predictors, predictors[i.min])
#print(paste("Mejor modelo de ", i, " variables", collapse = ""))
#print(init_predictors)
# Guardar las predictoras del modelo de i variables
listaPredictoras[[i]] <- init_predictors
}
print(paste("Modelos estimados ", modelosEstimados, collapse = ""))
return(listaPredictoras)
}
listaVar <- forward.stepwise.fn(dataset = Boston, target = "medv", 5)
# Esta función devuelve una lista con los nombres de las mejores p
# variables para explicar a la variable target,
# utilizando datos de ajuste en 'dataset'
forward.stepwise.fn <- function(dataset, target, p) {
# Arreglo de predictoras candidatas
predictors <- setdiff(colnames(dataset), target)
# Predictoras iniciales
init_predictors <- c("1")
# Variables auxiliares
listaPredictoras <- list()
modelosEstimados <- 0
# Validación de p
if (p > length(predictors)) {
p = 2
}
for (i in 1:p) {
# Obtener la lista de rss con cada variable
ss <- sapply(predictors, fit.model.fn,
predictors = init_predictors,
Ylabel = "medv", data = dataset)
modelosEstimados <- modelosEstimados + length(ss)
# Obtener el índice de variables que minimiza el ss
i.min <- which.min(ss)
# Agregar a la lista de predictores fijos y quitar de los candidatos
init_predictors <- union(init_predictors, predictors[i.min])
predictors <- setdiff(predictors, predictors[i.min])
print(paste("Mejor modelo de ", i, " variables", collapse = ""))
print(init_predictors)
# Guardar las predictoras del modelo de i variables
listaPredictoras[[i]] <- init_predictors
}
print(paste("Modelos estimados ", modelosEstimados, collapse = ""))
return(listaPredictoras)
}
listaVar <- forward.stepwise.fn(dataset = Boston, target = "medv", 5)
dataset <- Boston
target <- "medv"
listaVar <- forward.stepwise.fn(dataset = Boston, target = "medv", 5)
# Esta función devuelve una lista con los nombres de las mejores p
# variables para explicar a la variable target,
# utilizando datos de ajuste en 'dataset'
forward.stepwise.fn <- function(dataset, target, p) {
# Arreglo de predictoras candidatas
predictors <- setdiff(colnames(dataset), target)
# Predictoras iniciales
init_predictors <- c("1")
# Variables auxiliares
listaPredictoras <- list()
modelosEstimados <- 0
# Validación de p
if (p > length(predictors)) {
p = 2
}
for (i in 1:p) {
# Obtener la lista de rss con cada variable
ss <- sapply(predictors, fit.model.fn,
predictors = init_predictors,
Ylabel = "medv", data = dataset)
modelosEstimados <- modelosEstimados + length(ss)
# Obtener el índice de variables que minimiza el ss
i.min <- which.min(ss)
# Agregar a la lista de predictores fijos y quitar de los candidatos
init_predictors <- union(init_predictors, predictors[i.min])
predictors <- setdiff(predictors, predictors[i.min])
# Status
print(paste("Mejor modelo de ", i, " variables: ", collapse = ""))
print(init_predictors)
# Guardar las predictoras del modelo de i variables
listaPredictoras[[i]] <- init_predictors
}
print(paste("Fin. Modelos estimados: ", modelosEstimados, collapse = ""))
return(listaPredictoras)
}
listaVar <- forward.stepwise.fn(dataset = Boston, target = "medv", 5)
# Obtener la lista de mejores modelos
listaVar <- forward.stepwise.fn(dataset = Boston, target = "medv", 5)
# Validar los modelos para obtener el mejor
cv.models.fn(listaVar[[1]], Boston, target = "medv")
# Esta función recibe una lista de arreglos con los nombres de variables para estimar
# modelos y los valida utilizando 10-fold para escoger el mejor entre todos
cv.models.fn <- function(predictors, dataset, target) {
# Obtener la formula del modelo
formula <- paste(target, "~", paste(predictors, collapse = "+"), collapse = "")
print(formula)
}
# Validar los modelos para obtener el mejor
cv.models.fn(listaVar[[1]], Boston, target = "medv")
# Validar los modelos para obtener el mejor
cv.models.fn(listaVar[[4]], Boston, target = "medv")
print(fitness)
# Esta función recibe una lista de arreglos con los nombres de variables para estimar
# modelos y los valida utilizando 10-fold para escoger el mejor entre todos
cv.models.fn <- function(predictors, dataset, target, k = 10) {
# Función para obtener la medida de fitness sobre uno de los folds
get.fitness.measure <- function(foldIndex, data, formula, label) {
# Obtener los datos de ajuste y validación del modelo
trainData <- data[foldIndex, ]
cvData <- data[-foldIndex, ]
# Ajustar el modelo
lm.model <- lm(formula, data = trainData)
# Se obtiene la medida de fitness
# MSE sobre el conjunto de prueba
pred <- predict(lm.model, cvData)
fitness.measure <- sqrt(mean((cvData[[label]] - pred)^2))
return(fitness.measure)
}
# Obtener la formula del modelo
formula <- paste(target, "~", paste(predictors, collapse = "+"), collapse = "")
# Obtener los k folds para ajustar el modelo
folds <- createFolds(dataset[[label]], k = k, returnTrain = TRUE)
# Obtener las medidas de validación
fitness <- sapply(folds, get.fitness.measure,
data = dataset,
formula = formula,
label = target)
print(fitness)
}
# Validar los modelos para obtener el mejor
cv.models.fn(listaVar[[4]], Boston, target = "medv")
# Esta función recibe una lista de arreglos con los nombres de variables para estimar
# modelos y los valida utilizando 10-fold para escoger el mejor entre todos
cv.models.fn <- function(predictors, dataset, target, k = 10) {
# Función para obtener la medida de fitness sobre uno de los folds
get.fitness.measure <- function(foldIndex, data, formula, label) {
# Obtener los datos de ajuste y validación del modelo
trainData <- data[foldIndex, ]
cvData <- data[-foldIndex, ]
# Ajustar el modelo
lm.model <- lm(formula, data = trainData)
# Se obtiene la medida de fitness
# MSE sobre el conjunto de prueba
pred <- predict(lm.model, cvData)
fitness.measure <- sqrt(mean((cvData[[label]] - pred)^2))
return(fitness.measure)
}
# Obtener la formula del modelo
formula <- paste(target, "~", paste(predictors, collapse = "+"), collapse = "")
# Obtener los k folds para ajustar el modelo
folds <- createFolds(dataset[[target]], k = k, returnTrain = TRUE)
# Obtener las medidas de validación
fitness <- sapply(folds, get.fitness.measure,
data = dataset,
formula = formula,
label = target)
print(fitness)
}
# Validar los modelos para obtener el mejor
cv.models.fn(listaVar[[4]], Boston, target = "medv")
# Esta función recibe una lista de arreglos con los nombres de variables para estimar
# modelos y los valida utilizando 10-fold para escoger el mejor entre todos
cv.models.fn <- function(predictors, dataset, target, k = 10) {
# Función para obtener la medida de fitness sobre uno de los folds
get.fitness.measure <- function(foldIndex, data, formula, label) {
# Obtener los datos de ajuste y validación del modelo
trainData <- data[foldIndex, ]
cvData <- data[-foldIndex, ]
# Ajustar el modelo
lm.model <- lm(formula, data = trainData)
# Se obtiene la medida de fitness
# MSE sobre el conjunto de prueba
pred <- predict(lm.model, cvData)
fitness.measure <- sqrt(mean((cvData[[label]] - pred)^2))
return(fitness.measure)
}
# Obtener la formula del modelo
formula <- paste(target, "~", paste(predictors, collapse = "+"), collapse = "")
# Obtener los k folds para ajustar el modelo
folds <- createFolds(dataset[[target]], k = k, returnTrain = TRUE)
# Obtener las medidas de validación sobre cada fold
fitness <- sapply(folds, get.fitness.measure,
data = dataset,
formula = formula,
label = target)
# Devolver el promedio
return(mean(fitness))
}
# Validar los modelos para obtener el mejor
cv.models.fn(listaVar[[4]], Boston, target = "medv")
cvMeasures <- sapply(listaVar, cv.models.fn, dataset = Boston, target = "medv")
cvMeasures
# Obtener el mejor modelo:
i.minmdl <- which.min(cvMeasures)
listaVar[[i]]
listaVar[[i.mindmdl]]
listaVar[[i.minmdl]]
# Predictoras mejor modelo
listaVar[[i.minmdl]]
# Validar los modelos para obtener el mejor
cvMeasures <- sapply(listaVar, cv.models.fn, dataset = Boston, target = target)
target <- "medv"
p <- 13
# Obtener la lista de mejores modelos
listaVar <- forward.stepwise.fn(dataset = Boston, target = target, p)
# Validar los modelos para obtener el mejor
cvMeasures <- sapply(listaVar, cv.models.fn, dataset = Boston, target = target)
View(listaVar)
cvMeasures
modelo <- lm(formula = paste(target, "~", paste(listaVar[[i.minmdl]], collapse = "+"), collapse = ""),
data = dataset)
summary(modelo)
# Obtener el mejor modelo:
i.minmdl <- which.min(cvMeasures)
# Predictoras mejor modelo
listaVar[[i.minmdl]]
modelo <- lm(formula = paste(target, "~", paste(listaVar[[i.minmdl]], collapse = "+"), collapse = ""),
data = dataset)
summary(modelo)
source(file = "stepwise.r")
source(file = "stepwise.r")
source(file = "stepwise_fn.r")
# Cargamos librerías para demostración
library(MASS)
dataset <- Boston
target <- "medv"
p <- 13
listaVar <- forward.stepwise.fn(dataset = Boston, target = target, p)
cvMeasures <- sapply(listaVar, cv.models.fn, dataset = Boston, target = target)
cvMeasures
listaVar
dataset <- Boston
target <- "medv"
p <- 6
listaVar <- forward.stepwise.fn(dataset = Boston, target = target, p)
listaVar
cvMeasures <- sapply(listaVar, cv.models.fn, dataset = Boston, target = target)
cvMeasures
summary(modelo)
# Obtener el mejor modelo:
i.minmdl <- which.min(cvMeasures)
# Predictoras mejor modelo
listaVar[[i.minmdl]]
modelo <- lm(formula = paste(target, "~", paste(listaVar[[i.minmdl]], collapse = "+"), collapse = ""),
data = dataset)
summary(modelo)
