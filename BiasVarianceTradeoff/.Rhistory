}
return(fit)
}
0:10
:19
modl.var <- lapply(c(0:cmplx), sesgo.varianza.fn, df = data, B = 100, n = nrow(data))
cmplx = 10
modl.var <- lapply(c(0:cmplx), sesgo.varianza.fn, df = data, B = 100, n = nrow(data))
modl.var
modl.var
unlist(modl.var)
plot(x = 0:10, y = unlist(modl.var))
# Obtenemos todas las funciones de hipótesis en una misma estructura
all.hypothesis <- bind_rows(all.model.predictions, .id = "boot")
# Obtenemos la media con dplyr
mean_pred <- all.hypothesis %>%
group_by(input) %>%
summarise(mean_fn = mean(output))
# Graficamos las hipótesis en gris y los valores promedio en rojo
plot(data, pch=20, cex=0.25)
for(i in 1:nboots) {
points(all.model.predictions[[i]], col='gray', type='l')
}
points(mean_pred, type = 'l', col='red')
points(mean_pred, type = 'l', col='red')
# Obtenemos todas las funciones de hipótesis en una misma estructura
all.hypothesis <- bind_rows(all.model.predictions, .id = "boot")
# Obtenemos la media con dplyr
mean_pred <- all.hypothesis %>%
group_by(input) %>%
summarise(mean_fn = mean(output))
points(mean_pred, type = 'l', col='red')
# Graficamos las hipótesis en gris y los valores promedio en rojo
plot(data, pch=20, cex=0.25)
for(i in 1:nboots) {
points(all.model.predictions[[i]], col='gray', type='l')
}
plot(data, pch=20, cex=0.25)
for(i in 1:nboots) {
points(all.model.predictions[[i]], col='gray', type='l')
}
points(mean_pred, type = 'l', col='red')
boot_samples
test <- merge(x = boot_samples[[1]], y = mean_pred, by = "input")
View(test)
nrow(boot_samples)
nrow(boot_samples[[1]])
test <- boot_samples[[1]]
test
test$test= 1
View(test)
tfit <- fit_lm(boot_samples[[1]])
tfit
boot_samples[[1]]$f <- predict(tfit, tibble(input = boot_samples[[1]]$input))
head(boot_samples[[1]])
model_fitted_plotdata <- function(fit){
xaxis <- seq(min(data$input), max(data$input), by=0.01)
yaxis <- predict(fit, tibble(input = xaxis))
return(tibble(input = xaxis, output = yaxis))
}
# Definiciones para el ejercicio de bootstrap
nboots <- 100
bootsize <- nrow(data)
# Obtenemos las muestras de bootstrap en una lista
boot_samples <- lapply(1 : nboots, get_boot_sample, dataset = data, size = bootsize)
# Obtenemos una lista de modelos ajustados con la muestra y obtenemos los valores ajustados
all.models <- lapply(boot_samples, fit_lm, degree = 10)
all.model.predictions <- lapply(all.models, model_fitted_plotdata)
# Graficamos la población en una nube de puntos
plot(data, pch=20, cex=0.25)
# Graficamos los valores ajustados de todos los modelos
for(i in 1:nboots) {
# if (i %% 25 == 0) {
#   print(sprintf("Graficando modelo %d", i))
# }
points(all.model.predictions[[i]], col='gray', type='l')
}
# Graficamos la población en una nube de puntos
plot(data, pch=20, cex=0.25)
# Graficamos los valores ajustados de todos los modelos
for(i in 1:nboots) {
# if (i %% 25 == 0) {
#   print(sprintf("Graficando modelo %d", i))
# }
points(all.model.predictions[[i]], col='gray', type='l')
}
model_fitted_values <- function(fit, dataset) {
xaxis <- dataset$input
yaxis <- predict(fit, tibble(input = xaxis))
return(tibble(input = xaxis, output = dataset$output, f = yaxis))
}
all.models[[1]]
test <- model_fitted_values(all.models[[1]], boot_samples[[1]])
View(test)
all.fitted.values <- lapply(all.models, model_fitted_values, dataset=boot_samples)
all.models[[1]]
all.models[[1]]$fitted.values
all.models[[1]]$model
all.models[[1]]$fitted.values
head(all.models[[1]]$fitted.values)
head(all.models[[2]]$fitted.values)
all.models[[1]]
all.models[[1]]$fitted.values
head(boot_samples[[1]])
all.models[[1]]
boot_samples[[1]]$fitted <- all.models[[1]]$fitted.values
head(boot_samples[[1]])
boot_samples[[2]]$fitted <- all.models[[2]]$fitted.values
head(boot_samples[[2]])
boot_samples_mod <- boot_samples
for (i in 1:100) {}
for (i in 1:100) {
boot_samples_mod[[i]]$fitted <- all.models[[i]]$fitted.values
}
head(boot_samples_mod[[1]])
head(boot_samples_mod[[2]])
head(boot_samples_mod[[100]])
plot(x = 0:cmplx, y = unlist(modl.var))
data
head(data)
datatest <- data
datatest
datatest$f1 <- predict(all.models[[1]], tibble(input = datatest$input))
head(datatest)
datatest$(paste("f", 2))<- predict(all.models[[2]], tibble(input = datatest$input))
all.fitted.values <- lapply(all.models, model_fitted_values, dataset = data)
View(all.fitted.values)
head(all.fitted.values[[1]])
head(all.fitted.values[[2]])
datatest
head(datatest)
for (i in 1:100) {
modelo_str <- paste("f", i)
datatest[[modelo_str]] <- predict(all.models[[i]], tibble(input = datatest$input))
}
View(datatest)
d
datatest <- data
for (i in 1:100) {
modelo_str <- paste("f", i, sep = "")
datatest[[modelo_str]] <- predict(all.models[[i]], tibble(input = datatest$input))
}
datatest$f1 - datatest$f20
datatest[1]
head(datatest[1])
head(datatest[2])
head(rowSums(datatest[3:]))
datatest[3:]
ncol(datatest)
head(rowSums(datatest[3:102]))
test <- rowSums(datatest[3:102])
size(test)
test
length(test)
datatest$fhat <- rowSums(datatest[3:ncol(datatest)])/100
head(datatest$fhat)
View(all.fitted.values)
datatest <- data
for (i in 1:100) {
modelo_str <- paste("f", i, sep = "")
datatest[[modelo_str]] <- predict(all.models[[i]], tibble(input = datatest$input))
}
head(datatest)
prom <- datatest %>%
dplyr::select(starts_with("f"))
prom <- datatest %>%
dplyr::select(starts_with("f")) %>%
rowSums
prom
prom <- datatest %>%
dplyr::select(starts_with("f")) %>%
rowSums / 100
prom
f_hat <- datatest %>%
dplyr::select(starts_with("f")) %>%
rowSums / 100
f_hat_mean <- datatest %>%
dplyr::select(starts_with("f")) %>%
rowSums / 100
head(datatest$fhat)
test <- datatest %>% dplyr::select(starts_with("f")) - f_hat_mean
View(test)
test <- (datatest %>% dplyr::select(starts_with("f")) - f_hat_mean) ^2
View(test)
varX <- rowSums((datatest %>% dplyr::select(starts_with("f")) - f_hat_mean)^2)
varX
varX <- (1/(100-1)) * rowSums((datatest %>% dplyr::select(starts_with("f")) - f_hat_mean)^2)
varX
varianza
biasX <- (datatest$output - f_hat_mean)^2
biasX
length(sesgoX)
sesgoX <- (datatest$output - f_hat_mean)^2
length(sesgoX)
sesgo
# Estimando el sesgo
# Obtenemos un dataframe de todas las hipótesis en todos los valores y con los valores promedio
all.hypothesis.stat <- merge(x = all.hypothesis, y = mean_pred, by = "input")
sesgo.df <- all.hypothesis.stat %>%
mutate(sesgoIndv = (output - mean_fn), sesgoIndvSq = (output - mean_fn)^2) %>%
group_by(input) %>%
summarise(sesgoPromedioModelos = mean(sesgoIndv), varPromedioModelos = mean(sesgoIndvSq))
sesgo <- mean(sesgo.df$sesgoPromedioModelos)
varianza <- mean(sesgo.df$varPromedioModelos)
c(sesgo,varianza)
sesgoX <- (datatest$output - f_hat_mean)^2
sesgoX
sesgo <- mean(sesgoX)
sesgo
return(c("sesgo" = sesgo, "varianza" = varianza))
# Función para la varianza
sesgo.varianza.fn <- function(grado, df, B, n) {
print(sprintf("Generando modelo de complejidad %d", grado))
# Obtenemos las muestras de bootstrap en una lista
boot_samples <- lapply(1 : B, get_boot_sample, dataset = df, size = n)
# Obtenemos una lista de modelos ajustados con la muestra y obtenemos los valores ajustados
all.models <- lapply(boot_samples, fit_lm, degree = grado)
# Generamos los valores ajustados de todos los modelos
datatest <- df
for (i in 1:B) {
modelo_str <- paste("f", i, sep = "")
datatest[[modelo_str]] <- predict(all.models[[i]], tibble(input = datatest$input))
}
# Computamos los valores ajustados promedio
f_hat_mean <- datatest %>%
dplyr::select(starts_with("f")) %>%
rowSums / 100
# Obtenemos la varianza
varX <- (1/(B-1)) * rowSums((datatest %>% dplyr::select(starts_with("f")) - f_hat_mean)^2)
varianza <- mean(varX)
# Obtener el sesgo
sesgoX <- (datatest$output - f_hat_mean)^2
sesgo <- mean(sesgoX)
return(c("sesgo" = sesgo, "varianza" = varianza))
}
sesgo.varianza.fn(grado = 1, df = data, B = 100, n = nrow(data))
cmplx = 10
modl.var <- lapply(c(0:cmplx), sesgo.varianza.fn, df = data, B = 100, n = nrow(data))
modl.var
as.data.frame(do.call(rbind, modl.var))
as.data.frame(do.call(rbind, modl.var))
dataComplex
dataComplex <- as.data.frame(do.call(rbind, modl.var))
dataComplex[["GradoPolinomio"]] = 0:cmplx
dataComplex
plot(x=dataComplex$GradoPolinomio, y=dataComplex$sesgo, type = "l", col = "red")
line(x=dataComplex$GradoPolinomio, y=dataComplex$varianza, type = "l", col = "blue")
plot(x=dataComplex$GradoPolinomio, y=dataComplex$sesgo, type = "l", col = "red")
line(x=dataComplex$GradoPolinomio, y=dataComplex$varianza, type = "l", col = "blue")
plot(x=dataComplex$GradoPolinomio, y=dataComplex$sesgo, type = "l", col = "red")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$varianza, type = "l", col = "blue")
# Función para la varianza
sesgo.varianza.fn <- function(grado, df, B, n) {
print(sprintf("Generando modelo de complejidad %d", grado))
# Obtenemos las muestras de bootstrap en una lista
boot_samples <- lapply(1 : B, get_boot_sample, dataset = df, size = n)
# Obtenemos una lista de modelos ajustados con la muestra y obtenemos los valores ajustados
all.models <- lapply(boot_samples, fit_lm, degree = grado)
# Generamos los valores ajustados de todos los modelos
datatest <- df
for (i in 1:B) {
modelo_str <- paste("f", i, sep = "")
datatest[[modelo_str]] <- predict(all.models[[i]], tibble(input = datatest$input))
}
# Computamos los valores ajustados promedio
f_hat_mean <- datatest %>%
dplyr::select(starts_with("f")) %>%
rowSums / 100
# Obtenemos la varianza
varX <- (1/(B-1)) * rowSums((datatest %>% dplyr::select(starts_with("f")) - f_hat_mean)^2)
varianza <- mean(varX)
# Obtener el sesgo
sesgoX <- (datatest$output - f_hat_mean)^2
sesgo <- mean(sesgoX)
return(c("Sesgo" = sesgo, "Varianza" = varianza))
}
sesgo.varianza.fn(grado = 1, df = data, B = 100, n = nrow(data))
sesgo.varianza.fn(grado = 10, df = data, B = 100, n = nrow(data))
sesgo.varianza.fn(grado = 10, df = data, B = 1000, n = nrow(data))
sesgo.varianza.fn(grado = 10, df = data, B = 100, n = nrow(data))
sesgo.varianza.fn(grado = 10, df = data, B = 100, n = nrow(data))
cmplx = 10
modl.var <- lapply(c(0:cmplx), sesgo.varianza.fn, df = data, B = 500, n = nrow(data))
dataComplex <- as.data.frame(do.call(rbind, modl.var))
dataComplex[["GradoPolinomio"]] = 0:cmplx
dataComplex
plot(x=dataComplex$GradoPolinomio, y=dataComplex$sesgo, type = "l", col = "red")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$varianza, type = "l", col = "blue")
plot(x=dataComplex$GradoPolinomio, y=dataComplex$sesgo, type = "l", col = "red")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$varianza, type = "l", col = "blue")
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
cmplx = 10
modl.var <- lapply(c(0:cmplx), sesgo.varianza.fn, df = data, B = 100, n = nrow(data))
dataComplex <- as.data.frame(do.call(rbind, modl.var))
dataComplex[["GradoPolinomio"]] = 0:cmplx
dataComplex
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
ggplot(dataComplex, aes(x=GradoPolinomio, y=Sesgo)) + geom_line()
# Función para obtener un boot sample
get_boot_sample <- function(x, dataset, size) {
return(sample_n(dataset, size = size, replace = TRUE))
}
# Función para ajustar modelo de grado 'degree'
fit_lm <- function(dataset, degree = 2) {
if (degree == 0) {
fit <- lm("output ~ 1", data = dataset)
} else {
formula <- paste0("I(","input^", 1:degree, ")", collapse = '+')
formula <- paste0("output ~ ", formula)
fit <- lm(formula, data = dataset)
}
return(fit)
}
# Definiciones para el ejercicio de bootstrap
nboots <- 100
bootsize <- nrow(data)
# Obtenemos las muestras de bootstrap en una lista
boot_samples <- lapply(1 : nboots, get_boot_sample, dataset = data, size = bootsize)
# Obtenemos una lista de modelos ajustados con la muestra y obtenemos los valores ajustados
all.models <- lapply(boot_samples, fit_lm, degree = 10)
all.model.predictions <- lapply(all.models, model_fitted_plotdata)
f_hat_mean <- datatest %>%
dplyr::select(starts_with("f")) %>%
rowSums / 100
# Función para la varianza
sesgo.varianza.fn <- function(grado, df, B, n) {
print(sprintf("Generando modelo de complejidad %d", grado))
# Obtenemos las muestras de bootstrap en una lista
boot_samples <- lapply(1 : B, get_boot_sample, dataset = df, size = n)
# Obtenemos una lista de modelos ajustados con la muestra y obtenemos los valores ajustados
all.models <- lapply(boot_samples, fit_lm, degree = grado)
# Generamos los valores ajustados de todos los modelos
datatest <- df
for (i in 1:B) {
modelo_str <- paste("f", i, sep = "")
datatest[[modelo_str]] <- predict(all.models[[i]], tibble(input = datatest$input))
}
# Computamos los valores ajustados promedio
f_hat_mean <- datatest %>%
dplyr::select(starts_with("f")) %>%
rowSums / 100
# Obtenemos la varianza
varX <- (1/(B-1)) * rowSums((datatest %>% dplyr::select(starts_with("f")) - f_hat_mean)^2)
varianza <- mean(varX)
# Obtener el sesgo
sesgoX <- (datatest$output - f_hat_mean)^2
sesgo <- mean(sesgoX)
return(c("Sesgo" = sesgo, "Varianza" = varianza))
}
sesgo.varianza.fn(grado = 10, df = data, B = 100, n = nrow(data))
sesgo.varianza.fn(grado = 10, df = data, B = 100, n = nrow(data))
sesgo.varianza.fn(grado = 10, df = data, B = 100, n = nrow(data))
sesgo.varianza.fn(grado = 10, df = data, B = 100, n = nrow(data))
sesgo.varianza.fn(grado = 10, df = data, B = 100, n = nrow(data))
sesgo.varianza.fn(grado = 10, df = data, B = 100, n = nrow(data))
library(MASS)
library(dplyr)
# Carga de datos
data <- Boston %>%
dplyr::select(lstat,medv)
names(data)[1] <- "input"
names(data)[2] <- "output"
str(data)
# Función para obtener un boot sample
get_boot_sample <- function(x, dataset, size) {
return(sample_n(dataset, size = size, replace = TRUE))
}
# Función para ajustar modelo de grado 'degree'
fit_lm <- function(dataset, degree = 2) {
if (degree == 0) {
fit <- lm("output ~ 1", data = dataset)
} else {
formula <- paste0("I(","input^", 1:degree, ")", collapse = '+')
formula <- paste0("output ~ ", formula)
fit <- lm(formula, data = dataset)
}
return(fit)
}
# Esta función genera los valores de pronóstico para las gráficas
model_fitted_plotdata <- function(fit){
xaxis <- seq(min(data$input), max(data$input), by=0.01)
yaxis <- predict(fit, tibble(input = xaxis))
return(tibble(input = xaxis, output = yaxis))
}
model_fitted_values <- function(fit, dataset) {
xaxis <- dataset$input
yaxis <- predict(fit, tibble(input = xaxis))
return(tibble(input = xaxis, output = dataset$output, f = yaxis))
}
# Definiciones para el ejercicio de bootstrap
nboots <- 100
bootsize <- nrow(data)
# Obtenemos las muestras de bootstrap en una lista
boot_samples <- lapply(1 : nboots, get_boot_sample, dataset = data, size = bootsize)
# Obtenemos una lista de modelos ajustados con la muestra y obtenemos los valores ajustados
all.models <- lapply(boot_samples, fit_lm, degree = 10)
all.model.predictions <- lapply(all.models, model_fitted_plotdata)
# Obtenemos todas las funciones de hipótesis en una misma estructura
all.hypothesis <- bind_rows(all.model.predictions, .id = "boot")
# Obtenemos la media con dplyr
mean_pred <- all.hypothesis %>%
group_by(input) %>%
summarise(mean_fn = mean(output))
# Graficamos las hipótesis en gris y los valores promedio en rojo
plot(data, pch=20, cex=0.25)
for(i in 1:nboots) {
points(all.model.predictions[[i]], col='gray', type='l')
}
points(mean_pred, type = 'l', col='red')
datatest <- data
for (i in 1:100) {
modelo_str <- paste("f", i, sep = "")
datatest[[modelo_str]] <- predict(all.models[[i]], tibble(input = datatest$input))
}
head(datatest)
f_hat_mean <- datatest %>%
dplyr::select(starts_with("f")) %>%
rowSums / 100
varX <- (1/(100-1)) * rowSums((datatest %>% dplyr::select(starts_with("f")) - f_hat_mean)^2)
varianza <- mean(varX)
varianza
sesgoX <- (datatest$output - f_hat_mean)^2
sesgo <- mean(sesgoX)
sesgo
# Función para la varianza
sesgo.varianza.fn <- function(grado, df, B, n) {
print(sprintf("Generando modelo de complejidad %d", grado))
# Obtenemos las muestras de bootstrap en una lista
boot_samples <- lapply(1 : B, get_boot_sample, dataset = df, size = n)
# Obtenemos una lista de modelos ajustados con la muestra y obtenemos los valores ajustados
all.models <- lapply(boot_samples, fit_lm, degree = grado)
# Generamos los valores ajustados de todos los modelos
datatest <- df
for (i in 1:B) {
modelo_str <- paste("f", i, sep = "")
datatest[[modelo_str]] <- predict(all.models[[i]], tibble(input = datatest$input))
}
# Computamos los valores ajustados promedio
f_hat_mean <- datatest %>%
dplyr::select(starts_with("f")) %>%
rowSums / 100
# Obtenemos la varianza
varX <- (1/(B-1)) * rowSums((datatest %>% dplyr::select(starts_with("f")) - f_hat_mean)^2)
varianza <- mean(varX)
# Obtener el sesgo
sesgoX <- (datatest$output - f_hat_mean)^2
sesgo <- mean(sesgoX)
return(c("Sesgo" = sesgo, "Varianza" = varianza))
}
cmplx = 10
modl.var <- lapply(c(0:cmplx), sesgo.varianza.fn, df = data, B = 100, n = nrow(data))
dataComplex <- as.data.frame(do.call(rbind, modl.var))
dataComplex[["GradoPolinomio"]] = 0:cmplx
dataComplex
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
modl.var <- lapply(c(0:cmplx), sesgo.varianza.fn, df = data, B = 100, n = nrow(data))
dataComplex <- as.data.frame(do.call(rbind, modl.var))
dataComplex[["GradoPolinomio"]] = 0:cmplx
dataComplex
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
modl.var <- lapply(c(0:cmplx), sesgo.varianza.fn, df = data, B = 100, n = nrow(data))
dataComplex <- as.data.frame(do.call(rbind, modl.var))
dataComplex[["GradoPolinomio"]] = 0:cmplx
dataComplex
cmplx = 10
modl.var <- lapply(c(0:cmplx), sesgo.varianza.fn, df = data, B = 200, n = nrow(data))
dataComplex <- as.data.frame(do.call(rbind, modl.var))
dataComplex[["GradoPolinomio"]] = 0:cmplx
dataComplex
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
rm(list=c("datatest"))
cmplx = 10
modl.var <- lapply(c(0:cmplx), sesgo.varianza.fn, df = data, B = 100, n = nrow(data))
dataComplex <- as.data.frame(do.call(rbind, modl.var))
dataComplex[["GradoPolinomio"]] = 0:cmplx
dataComplex
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
cmplx = 10
modl.var <- lapply(c(0:cmplx), sesgo.varianza.fn, df = data, B = 100, n = nrow(data))
cmplx = 10
modl.var <- lapply(c(0:cmplx), sesgo.varianza.fn, df = data, B = 100, n = nrow(data))
dataComplex <- as.data.frame(do.call(rbind, modl.var))
dataComplex[["GradoPolinomio"]] = 0:cmplx
dataComplex
cmplx = 30
modl.var <- lapply(c(0:cmplx), sesgo.varianza.fn, df = data, B = 100, n = nrow(data))
dataComplex <- as.data.frame(do.call(rbind, modl.var))
dataComplex[["GradoPolinomio"]] = 0:cmplx
dataComplex
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
cmplx = 12
modl.var <- lapply(c(0:cmplx), sesgo.varianza.fn, df = data, B = 100, n = nrow(data))
dataComplex <- as.data.frame(do.call(rbind, modl.var))
dataComplex[["GradoPolinomio"]] = 0:cmplx
dataComplex
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red",
xlab = "Grado del polinomio",
ylab = "Variabilidad del error")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
plot(x=dataComplex$GradoPolinomio, y=dataComplex$Sesgo, type = "l", col = "red",
xlab = "Grado del polinomio")
lines(x=dataComplex$GradoPolinomio, y=dataComplex$Varianza, type = "l", col = "blue")
exit
